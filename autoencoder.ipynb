{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder for MNIST compared to supervised model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector size for latent variables and number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the autoencoder model consisting of an encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder using CNN layers\n",
    "encoder = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(LATENT_SIZE, activation=\"relu\")\n",
    "])\n",
    "\n",
    "decoder = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(7 * 7 * 32, input_shape=(LATENT_SIZE,)),\n",
    "    tf.keras.layers.Reshape((7, 7, 32)),\n",
    "    tf.keras.layers.Conv2DTranspose(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.UpSampling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2DTranspose(16, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.UpSampling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2DTranspose(1, (3, 3), activation=\"sigmoid\", padding=\"same\"),\n",
    "    tf.keras.layers.Reshape((28, 28))\n",
    "])\n",
    "\n",
    "img = tf.keras.layers.Input(shape = (28, 28))\n",
    "latent_vector = encoder(img)\n",
    "output = decoder(latent_vector)\n",
    "autoencoder = tf.keras.models.Model(inputs = img, outputs = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 34s 17ms/step - loss: 0.1125\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0858\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0828\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0813\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0803\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0795\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0790\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0785\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0782\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139a594d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(\"nadam\", loss = \"binary_crossentropy\")\n",
    "\n",
    "autoencoder.fit(x_train, x_train, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model with supervised learning with 10% of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 1s 8ms/step - loss: 2.6032 - accuracy: 0.1250\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2.0054 - accuracy: 0.4117\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.5598 - accuracy: 0.5950\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.0369 - accuracy: 0.7217\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.7917\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5162 - accuracy: 0.8383\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4100 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.3342 - accuracy: 0.9017\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.2895 - accuracy: 0.9233\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.2556 - accuracy: 0.9417\n",
      "Accuracy after fine-tuning: [0.40163785219192505, 0.8738999962806702]\n"
     ]
    }
   ],
   "source": [
    "# Set up the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Use 1% of the labeled training examples for supervised learning\n",
    "x_train_supervised = x_train[:600]\n",
    "y_train_supervised = y_train[:600]\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x_train_supervised,\n",
    "    y_train_supervised,\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Accuracy after fine-tuning: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
